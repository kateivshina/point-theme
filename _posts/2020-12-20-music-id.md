---
title: Music Identification with Persistent Homology
---


**The full paper is available [here](/files/music_id.pdf).**

```python
markdown = Redcarpet.new("Hello World!")
print('hello world')
```


In this article, I introduce my approach to music identification, applying ideas from the field of Topological Data Analysis (TDA). TDA is an emerging field of data analysis, and TDA tools have found successful applications in the area of machine learning.

I will first define the research problem and then discuss my approach, dataset and the results.

## Background

Have you ever wished to know the name of the song you just heard at a bar? If you’re a music lover like me, then the answer is probably yes. While humans can identify a familiar song in ~2 seconds, teaching a computer to do the same is a difficult task. Currently, audio identification is an active area of research in the Music Information Retrieval community.

Observing recent advances in understanding music through geometric lens, which was pioneered by Dmitri Tymoczko in his “A Geometry of Music” book, I have asked myself: how can we use the geometry/topology of music to fingerprint the songs?

## Problem Statement

In this work, I aim to find a representation of songs as a time series of topological fingerprints, with a metric to compare pairs of time-varying shapes. I then develop and test an algorithm that can account for noise distortions of input audio clips to identify music.

**Task**: for a given input music clip, find its closest match in the database and return the name of the song.

Thus, we first need to find suitable representation of musical data, extract signatures, then create a database of the signatures with labels — names of the songs, and finally apply the search algorithm to new noisy samples.

## Theory

The main tool of TDA is persistent homology — a way of computing topological features of data at different scales. In short, the idea is to build filtrations of data and see how certain homology group invariants (Betti numbers) change at different spatial resolutions. Gary Koplik provides a nice [introduction](https://towardsdatascience.com/persistent-homology-with-examples-1974d4b9c3d0) to persistent homology that you should read. For the purposes of this article, all you need to understand is that persistent homology can be used to measure holes — when they appear and die — in a geometric object and this information can be used as a signature of the data.


| ![name](/files/music_id/tor-removebg-copy.png) | 
|:--:| 
| Deformed torus |


## Approach

### *Extracting signatures*

I will start by discussing the way I extract signatures from music clips. The first step is to produce constant-Q chromograms from the clips of the songs. To produce such chromograms, I apply constant-Q transform, which transforms a time series to the frequency domain. This transformation is related to the Fourier transform and is said to be well suited for musical data, as it outputs amplitude against log frequency. The constant-Q transform of x[n] is defined as follows:


![Definition of the constant-Q transform](/files/music_id/cqt.png)

Example constant-Q chromogram is shown below.
![Example of a constant-Q chromogram.](/files/music_id/chroma_cqt.png)

### *Deforming Tonnetz*

Next, we project the chromogram onto Tonnetz and deform it by defining a height function. In music theory, Tonnetz is a lattice diagram that represents pitch space, allowing to capture certain harmonic relationships in musical data (see figures below). It was first described by Leonhard Euler in 1739. When studying harmony, Leonard Euler put notes on a torus such that in the horizontal direction, notes are separated by perfect 5th, in a diagonal direction (from left to right), notes are separated by major 3rd, and in another diagonal direction (from right to left), notes are separated by minor 3rd.

| ![name](/files/music_id/tonnetz.png) | 
|:--:| 
| Neo-Riemannian Tonnetz. Source: Wikipedia |
 

| ![name](/files/music_id/TonnetzTorus.gif) | 
|:--:| 
| Tonnetz viewed as a torus. Source: Wikipedia |
 


The set of pitch classes is R/12Z (i.e. we have 12 semitones in total, and we identify notes that are an octave apart). We place each pitch class onto the Tonnetz as a vertex. We then define a height function h : V → R on the set of vertices of the space R/12Z (each vertex is a pitch class) by associating to each vertex a height that corresponds to the amplitude of a given pitch class in the music clip. After that, the 2-dimensional Tonnetz is deformed, having the values of the height function as its third dimension. Below is an example of the Tonnetz deformed by 2-seconds clip of blues.


| ![name](/files/music_id/deformed.png) | 
|:--:| 
| Deformed Tonnetz (2 seconds of blues) |
 
 

### *Persistent diagrams*

After finding a way to represent musical data as a topological object, I then apply upper-star filtration to the deformed Tonnetz to produce persistent diagrams.


| ![name](/files/music_id/pd.png) | 
|:--:| 
| Persistent diagrams of three 2-seconds clips |
 

In general, persistent homology is useful because, for example, changing the speed of a recording doesn’t alter persistent diagrams that are based on lower-star filtration that much (so we can identify DJ remixes of a song). Figure below illustrates this fact. Given a simplicial complex K and a real-valued function f defined on its vertices, define K_a = {σ ∈ K|max_{v∈σ} : f(v) ≤ a} to be the lower-star filtration.

| ![name](/files/music_id/star_filtration.png) | 
|:--:| 
| Reparameterizing time-series does not change the original persistent diagram. |
 
 
### *Matching*

After producing persistent diagrams, I calculate the bottleneck distances between the persistent diagrams to find the closest match of a given song. The bottleneck distance is a metric on the space of persistent diagrams that is defined as follows:


![Definition of the Bottleneck distance](/files/music_id/distance.png)

With mild assumptions on the function, the authors of [1] have showed that the persistent diagram of a function on a topological space is stable. Persistent homology is thus claimed to be stable under small changes in the input filtration (so that such changes lead to small perturbations in the bottleneck distance). Hence, bottleneck distance provides us with information on how similar two persistent diagrams are.

## Dataset

The dataset consisted of fifty 30-seconds-long songs from 10 genres (5 songs per genre).

The genres are:

- blues
- classical
- country
- disco
- EDM
- jazz
- punk rock
- pop
- rap
- rock

## Results

As mentioned above, I compiled a database of 50 songs from 10 genres, with 5 songs per genre. As input to the algorithm, I use .WAV files containing 1, 2, 3, 4, 5-seconds clips of songs. To test the algorithm, I added noise from a normal distribution so that the song clips have signal-to-noise ratio SNR = 10, 20, 30. I then ran the algorithm to identify music within each genre. The accuracy as a function of clip duration for different SNR is reported in the figure below. From [2], it follows that Shazam computes ~50,000–250,000 fingerprints per song. I compute 1 persistent diagram per clip, so I produce ~10,000–20,000 signatures per song.

| ![name](/files/music_id/snr.png) | 
|:--:| 
| Accuracy as a function of clip duration of a given SNR |
 


## Discussion

1) Though the algorithm performs well, calculating the bottleneck distance is computationally expensive.

2) The height function we defined above is the simplest one. We could also use discrete Gaussian curvature as our height function to reflect different geometries of the Tonnetz. Furthermore, we can capture additional harmonic information using a consonance function as our height function, which would give information on tensions/resolutions of chords in a clip.

3) While in this article I only utilized the vertical structure of music (i.e. pitch classes), it is important to consider the horizontal structure as well, i.e. chords’ time progression, tempo, etc. (after all, it is important in what order we hear the chords/notes). Additionally, the rhythmic part of musical pieces is important, and we could capture this additional information using audio novelty function.


## References

[1] David Cohen-Steiner, Herbert Edelsbrunner, and John Harer. Stability of persistence diagrams. Discrete Computational Geometry, 37:103–120, 2007.

[2] Avery Wang. An industrial strength audio search algorithm. 01 2003.
